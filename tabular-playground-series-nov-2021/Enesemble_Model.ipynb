{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mplt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e887e1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106643</td>\n",
       "      <td>3.59437</td>\n",
       "      <td>132.8040</td>\n",
       "      <td>3.18428</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>1.18859</td>\n",
       "      <td>3.73238</td>\n",
       "      <td>2.266270</td>\n",
       "      <td>2.09959</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09862</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>-0.011715</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>4.211250</td>\n",
       "      <td>1.97877</td>\n",
       "      <td>0.085974</td>\n",
       "      <td>0.240496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125021</td>\n",
       "      <td>1.67336</td>\n",
       "      <td>76.5336</td>\n",
       "      <td>3.37825</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>5.09366</td>\n",
       "      <td>1.27562</td>\n",
       "      <td>-0.471318</td>\n",
       "      <td>4.54594</td>\n",
       "      <td>0.037706</td>\n",
       "      <td>...</td>\n",
       "      <td>3.46017</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.124863</td>\n",
       "      <td>0.154064</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>-0.267928</td>\n",
       "      <td>2.57786</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>0.024719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036330</td>\n",
       "      <td>1.49747</td>\n",
       "      <td>233.5460</td>\n",
       "      <td>2.19435</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>3.12694</td>\n",
       "      <td>5.05687</td>\n",
       "      <td>3.849460</td>\n",
       "      <td>1.80187</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>...</td>\n",
       "      <td>4.88300</td>\n",
       "      <td>0.085222</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>0.116092</td>\n",
       "      <td>-0.001688</td>\n",
       "      <td>-0.520069</td>\n",
       "      <td>2.14112</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.148209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014077</td>\n",
       "      <td>0.24600</td>\n",
       "      <td>779.9670</td>\n",
       "      <td>1.89064</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>1.53112</td>\n",
       "      <td>2.69800</td>\n",
       "      <td>4.517330</td>\n",
       "      <td>4.50332</td>\n",
       "      <td>0.123494</td>\n",
       "      <td>...</td>\n",
       "      <td>3.47439</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>-0.008100</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.511657</td>\n",
       "      <td>1.96860</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003259</td>\n",
       "      <td>3.71542</td>\n",
       "      <td>156.1280</td>\n",
       "      <td>2.14772</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>2.09859</td>\n",
       "      <td>4.15492</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>3.37145</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91059</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>0.125072</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>1.043790</td>\n",
       "      <td>1.07481</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.072798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0       f1        f2       f3        f4       f5       f6        f7  \\\n",
       "0  0.106643  3.59437  132.8040  3.18428  0.081971  1.18859  3.73238  2.266270   \n",
       "1  0.125021  1.67336   76.5336  3.37825  0.099400  5.09366  1.27562 -0.471318   \n",
       "2  0.036330  1.49747  233.5460  2.19435  0.026914  3.12694  5.05687  3.849460   \n",
       "3 -0.014077  0.24600  779.9670  1.89064  0.006948  1.53112  2.69800  4.517330   \n",
       "4 -0.003259  3.71542  156.1280  2.14772  0.018284  2.09859  4.15492 -0.038236   \n",
       "\n",
       "        f8        f9  ...      f91       f92       f93       f94       f95  \\\n",
       "0  2.09959  0.012330  ...  1.09862  0.013331 -0.011715  0.052759  0.065400   \n",
       "1  4.54594  0.037706  ...  3.46017  0.017054  0.124863  0.154064  0.606848   \n",
       "2  1.80187  0.056995  ...  4.88300  0.085222  0.032396  0.116092 -0.001688   \n",
       "3  4.50332  0.123494  ...  3.47439 -0.017103 -0.008100  0.062013  0.041193   \n",
       "4  3.37145  0.034166  ...  1.91059 -0.042943  0.105616  0.125072  0.037509   \n",
       "\n",
       "        f96      f97       f98       f99  target  \n",
       "0  4.211250  1.97877  0.085974  0.240496       0  \n",
       "1 -0.267928  2.57786 -0.020877  0.024719       0  \n",
       "2 -0.520069  2.14112  0.124464  0.148209       0  \n",
       "3  0.511657  1.96860  0.040017  0.044873       0  \n",
       "4  1.043790  1.07481 -0.012819  0.072798       1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"./data/train.csv\", sep = \",\") ##Add your own path to access data\n",
    "data_train=data_train.drop(['id'], axis=1) \n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ef1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_train.drop(columns = 'target'), data_train['target'], \n",
    "                                                    test_size = 0.25)\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0e5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "znormalizer = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "X=data_train.drop(columns = 'target')\n",
    "y=data_train['target']\n",
    "num_cols = X_train.select_dtypes(['integer', 'float']).columns\n",
    "\n",
    "znormalizer.fit(X_train[num_cols])\n",
    "robust_scaler.fit(X_train[num_cols])\n",
    "\n",
    "X_train_norm = pd.DataFrame(znormalizer.transform(X_train[num_cols]), columns = num_cols)\n",
    "X_test_norm = pd.DataFrame(znormalizer.transform(X_test[num_cols]), columns = num_cols)\n",
    "\n",
    "X_train_robust = pd.DataFrame(robust_scaler.transform(X_train[num_cols]), columns = num_cols)\n",
    "X_test_robust = pd.DataFrame(robust_scaler.transform(X_test[num_cols]), columns = num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e913a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score = 74.92015638%  of Logistic Regression Model on the training data.\n",
      "ROC_AUC Score = 74.92631427%  of Logistic Regression Model on the validation data.\n"
     ]
    }
   ],
   "source": [
    "##Best Logistic Regression\n",
    "best_LR= LogisticRegression(C=0.0002, \n",
    "                solver='saga', \n",
    "                penalty='l2', \n",
    "                fit_intercept=False,\n",
    "                max_iter=400\n",
    "                )\n",
    "\n",
    "best_LR.fit(X_train_norm, y_train)\n",
    "\n",
    "y_hat_train_logit_proba = best_LR.predict_proba(X_train_norm)[::,1]\n",
    "y_hat_test_logit_proba = best_LR.predict_proba(X_test_norm)[::,1]\n",
    "\n",
    "auc_score_train_logit = roc_auc_score(y_train, y_hat_train_logit_proba) * 100\n",
    "auc_score_test_logit = roc_auc_score(y_test, y_hat_test_logit_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.8f}%  of Logistic Regression Model on the training data.\".format(auc_score_train_logit))\n",
    "print(\"ROC_AUC Score = {:.8f}%  of Logistic Regression Model on the validation data.\".format(auc_score_test_logit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5985176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Best XGBClassifier\n",
    "best_XGBC= XGBClassifier(objective='binary:logistic', \n",
    "                         eval_metric='aucpr', \n",
    "                         gamma=0.05, \n",
    "                         subsample=0.6, \n",
    "                         min_child_weight=1, \n",
    "                         random_state =0, \n",
    "                         booster='gbtree', \n",
    "                         learning_rate=0.05, \n",
    "                         max_depth=3, \n",
    "                         reg_lambda=0.1, \n",
    "                         reg_alpha=0.3, \n",
    "                         n_estimators=1500)\n",
    "\n",
    "best_XGBC.fit(X_train_norm, y_train)\n",
    "\n",
    "y_hat_train_xgbc_proba = best_XGBC.predict_proba(X_train_norm)[::,1]\n",
    "y_hat_test_xgbc_proba = best_XGBC.predict_proba(X_test_norm)[::,1]\n",
    "\n",
    "auc_score_train_xgbc = roc_auc_score(y_train, y_hat_train_xgbc_proba) * 100\n",
    "auc_score_test_xgbc = roc_auc_score(y_test, y_hat_test_xgbc_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.8f}%  of XGBoost Classifier Model on the training data.\".format(auc_score_train_xgbc))\n",
    "print(\"ROC_AUC Score = {:.8f}%  of XGBoost Classifier Model on the validation data.\".format(auc_score_test_xgbc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427fc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Best LinearSVC\n",
    "\n",
    "best_LinearSVC=LinearSVC(penalty='l2', \n",
    "                         loss='hinge', \n",
    "                         #tol=0.0001, \n",
    "                         C=0.001, \n",
    "                         fit_intercept=False, \n",
    "                         #verbose=0, \n",
    "                         #random_state=None, \n",
    "                         max_iter=1500)\n",
    "\n",
    "best_LinearSVC.fit(X_train_norm, y_train)\n",
    "\n",
    "cclf = CalibratedClassifierCV(base_estimator=best_LinearSVC, method='sigmoid', cv='prefit')\n",
    "\n",
    "cclf.fit(X_train_norm, y_train)\n",
    "\n",
    "y_hat_train_cclf_proba=cclf.predict_proba(X_train_norm)[::,1]\n",
    "y_hat_test_cclf_proba=cclf.predict_proba(X_test_norm)[::,1]\n",
    "\n",
    "auc_score_train_cclf = roc_auc_score(y_train, y_hat_train_cclf_proba) * 100\n",
    "auc_score_test_cclf = roc_auc_score(y_test, y_hat_test_cclf_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.8f}%  of LinearSVC Model on the training data.\".format(auc_score_train_cclf))\n",
    "print(\"ROC_AUC Score = {:.8f}%  of LinearSVC Model on the validation data.\".format(auc_score_test_cclf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Best Keras Classifier\n",
    "# create model\n",
    "\n",
    "def create_keras_sequential_model(optimizer='adam', init='glorot_uniform'):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=100, kernel_initializer=init, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(64, kernel_initializer=init, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(32, kernel_initializer=init, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(16, kernel_initializer=init, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\t\n",
    "\tmodel.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "\treturn model\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/13669\n",
    "# http://rasbt.github.io/mlxtend/\n",
    "best_keras = KerasClassifier(build_fn=create_keras_sequential_model,\n",
    "                             optimizer='adam', \n",
    "                             epochs=140, \n",
    "                             batch_size=2048, \n",
    "                             init='glorot_uniform', \n",
    "                             verbose=0)\n",
    "best_keras._estimator_type = 'classifier'\n",
    "\n",
    "best_keras.fit(X_train_norm, y_train)\n",
    "\n",
    "y_hat_train_keras_proba=best_keras.predict_proba(X_train_norm)[::,1]\n",
    "y_hat_test_keras_proba=best_keras.predict_proba(X_test_norm)[::,1]\n",
    "\n",
    "auc_score_train_keras = roc_auc_score(y_train, y_hat_train_keras_proba) * 100\n",
    "auc_score_test_keras = roc_auc_score(y_test, y_hat_test_keras_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.8f}%  of NN Model on the training data.\".format(auc_score_train_keras))\n",
    "print(\"ROC_AUC Score = {:.8f}%  of NN Model on the validation data.\".format(auc_score_test_keras))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87566ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Add Ensemble Model Code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500312f",
   "metadata": {},
   "source": [
    "## Ensemble - StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a63c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('LR', best_LR), ('XGBC', best_XGBC), ('LinearSVC', best_LinearSVC), ('keras', best_keras)]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Stacking model score: %.8f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81040d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcebb664",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
