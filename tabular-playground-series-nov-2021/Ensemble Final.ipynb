{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mplt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106643</td>\n",
       "      <td>3.59437</td>\n",
       "      <td>132.8040</td>\n",
       "      <td>3.18428</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>1.18859</td>\n",
       "      <td>3.73238</td>\n",
       "      <td>2.266270</td>\n",
       "      <td>2.09959</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09862</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>-0.011715</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>4.211250</td>\n",
       "      <td>1.97877</td>\n",
       "      <td>0.085974</td>\n",
       "      <td>0.240496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125021</td>\n",
       "      <td>1.67336</td>\n",
       "      <td>76.5336</td>\n",
       "      <td>3.37825</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>5.09366</td>\n",
       "      <td>1.27562</td>\n",
       "      <td>-0.471318</td>\n",
       "      <td>4.54594</td>\n",
       "      <td>0.037706</td>\n",
       "      <td>...</td>\n",
       "      <td>3.46017</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.124863</td>\n",
       "      <td>0.154064</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>-0.267928</td>\n",
       "      <td>2.57786</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>0.024719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036330</td>\n",
       "      <td>1.49747</td>\n",
       "      <td>233.5460</td>\n",
       "      <td>2.19435</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>3.12694</td>\n",
       "      <td>5.05687</td>\n",
       "      <td>3.849460</td>\n",
       "      <td>1.80187</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>...</td>\n",
       "      <td>4.88300</td>\n",
       "      <td>0.085222</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>0.116092</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.520069</td>\n",
       "      <td>2.14112</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.148209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014077</td>\n",
       "      <td>0.24600</td>\n",
       "      <td>779.9670</td>\n",
       "      <td>1.89064</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>1.53112</td>\n",
       "      <td>2.69800</td>\n",
       "      <td>4.517330</td>\n",
       "      <td>4.50332</td>\n",
       "      <td>0.123494</td>\n",
       "      <td>...</td>\n",
       "      <td>3.47439</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>-0.008100</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.511657</td>\n",
       "      <td>1.96860</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003259</td>\n",
       "      <td>3.71542</td>\n",
       "      <td>156.1280</td>\n",
       "      <td>2.14772</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>2.09859</td>\n",
       "      <td>4.15492</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>3.37145</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91059</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>0.125072</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>1.043790</td>\n",
       "      <td>1.07481</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.072798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0       f1        f2       f3        f4       f5       f6        f7  \\\n",
       "0  0.106643  3.59437  132.8040  3.18428  0.081971  1.18859  3.73238  2.266270   \n",
       "1  0.125021  1.67336   76.5336  3.37825  0.099400  5.09366  1.27562 -0.471318   \n",
       "2  0.036330  1.49747  233.5460  2.19435  0.026914  3.12694  5.05687  3.849460   \n",
       "3 -0.014077  0.24600  779.9670  1.89064  0.006948  1.53112  2.69800  4.517330   \n",
       "4 -0.003259  3.71542  156.1280  2.14772  0.018284  2.09859  4.15492 -0.038236   \n",
       "\n",
       "        f8        f9  ...      f91       f92       f93       f94       f95  \\\n",
       "0  2.09959  0.012330  ...  1.09862  0.013331 -0.011715  0.052759  0.065400   \n",
       "1  4.54594  0.037706  ...  3.46017  0.017054  0.124863  0.154064  0.606848   \n",
       "2  1.80187  0.056995  ...  4.88300  0.085222  0.032396  0.116092 -0.001689   \n",
       "3  4.50332  0.123494  ...  3.47439 -0.017103 -0.008100  0.062013  0.041193   \n",
       "4  3.37145  0.034166  ...  1.91059 -0.042943  0.105616  0.125072  0.037509   \n",
       "\n",
       "        f96      f97       f98       f99  target  \n",
       "0  4.211250  1.97877  0.085974  0.240496       0  \n",
       "1 -0.267928  2.57786 -0.020877  0.024719       0  \n",
       "2 -0.520069  2.14112  0.124464  0.148209       0  \n",
       "3  0.511657  1.96860  0.040017  0.044873       0  \n",
       "4  1.043790  1.07481 -0.012819  0.072798       1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"./data/train.csv\", sep = \",\") ##Add your own path to access data\n",
    "data_train=data_train.drop(['id'], axis=1) \n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_train.drop(columns = 'target')\n",
    "y=data_train['target']\n",
    "\n",
    "X_train, X_valid, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.25, random_state=0)\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_valid = X_valid.reset_index(drop = True)\n",
    "\n",
    "znormalizer = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "num_cols = X.select_dtypes(['integer', 'float']).columns\n",
    "\n",
    "znormalizer.fit(X_train[num_cols])\n",
    "robust_scaler.fit(X_train[num_cols])\n",
    "\n",
    "X_train_norm = pd.DataFrame(znormalizer.transform(X_train[num_cols]), columns = num_cols)\n",
    "X_valid_norm = pd.DataFrame(znormalizer.transform(X_valid[num_cols]), columns = num_cols)\n",
    "\n",
    "X__train_robust = pd.DataFrame(robust_scaler.transform(X_train[num_cols]), columns = num_cols)\n",
    "X_valid_robust = pd.DataFrame(robust_scaler.transform(X_valid[num_cols]), columns = num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "znormalizer.fit(X[num_cols])\n",
    "robust_scaler.fit(X[num_cols])\n",
    "\n",
    "X_norm = pd.DataFrame(znormalizer.transform(X[num_cols]), columns = num_cols)\n",
    "X_robust = pd.DataFrame(robust_scaler.transform(X[num_cols]), columns = num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score = 74.92%  of Logistic Regression Model on ALL the data.\n"
     ]
    }
   ],
   "source": [
    "##Best Logistic Regression (Kaggle Score 0.74554)\n",
    "\n",
    "best_LR= LogisticRegression(C=0.0002, \n",
    "                solver='saga', \n",
    "                penalty='l2', \n",
    "                fit_intercept=False,\n",
    "                max_iter=400\n",
    "                )\n",
    "\n",
    "best_LR.fit(X_norm, y)\n",
    "#best_LR.fit(X_train_norm, y_train)\n",
    "\n",
    "y_hat_ALL_logit_proba = best_LR.predict_proba(X_norm)[::,1]\n",
    "#y_hat_train_logit_proba = best_LR.predict_proba(X_train_norm)[::,1]\n",
    "#y_hat_valid_logit_proba = best_LR.predict_proba(X_valid_norm)[::,1]\n",
    "\n",
    "auc_score_ALL_logit = roc_auc_score(y, y_hat_ALL_logit_proba) * 100\n",
    "#auc_score_train_logit = roc_auc_score(y_test, y_hat_train_logit_proba) * 100\n",
    "#auc_score_valid_logit = roc_auc_score(y_test, y_hat_valid_logit_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.2f}%  of Logistic Regression Model on ALL the data.\".format(auc_score_ALL_logit))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of Logistic Regression Model on the training data.\".format(auc_score_train_logit))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of Logistic Regression Model on the validation data.\".format(auc_score_valid_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score = 74.93%  of LinearSVC Model on ALL the data.\n"
     ]
    }
   ],
   "source": [
    "###Best LinearSVC (Kaggle Score 0.74582)\n",
    "\n",
    "best_LinearSVC=LinearSVC(penalty='l2', \n",
    "                         loss='hinge', \n",
    "                         #tol=0.0001, \n",
    "                         C=0.001, \n",
    "                         fit_intercept=False, \n",
    "                         #verbose=0, \n",
    "                         #random_state=None, \n",
    "                         max_iter=1500)\n",
    "\n",
    "best_LinearSVC.fit(X_norm, y)\n",
    "#best_LinearSVC.fit(X__train_norm, y_train)\n",
    "\n",
    "cclf = CalibratedClassifierCV(base_estimator=best_LinearSVC, method='sigmoid', cv='prefit')\n",
    "\n",
    "cclf.fit(X_norm, y)\n",
    "#cclf.fit(X_train_norm, y_train)\n",
    "\n",
    "y_hat_ALL_cclf_proba=cclf.predict_proba(X_norm)[::,1]\n",
    "#y_hat_train_cclf_proba=cclf.predict_proba(X_train_norm)[::,1]\n",
    "#y_hat_valid_cclf_proba=cclf.predict_proba(X_valid_norm)[::,1]\n",
    "\n",
    "auc_score_ALL_cclf = roc_auc_score(y, y_hat_ALL_cclf_proba) * 100\n",
    "#auc_score_train_cclf = roc_auc_score(y_test, y_hat_train_cclf_proba) * 100\n",
    "#auc_score_valid_cclf = roc_auc_score(y_test, y_hat_valid_cclf_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.2f}%  of LinearSVC Model on ALL the data.\".format(auc_score_ALL_cclf))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of LinearSVC Model on the training data.\".format(auc_score_train_cclf))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of LinearSVC Model on the validation data.\".format(auc_score_valid_cclf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score = 76.05%  of XGBoost Classifier Model on ALL the data.\n"
     ]
    }
   ],
   "source": [
    "###Best XGBClassifier (Kaggle Score 0.74013)\n",
    "\n",
    "best_XGBC= XGBClassifier(objective='binary:logistic', \n",
    "                         eval_metric='aucpr', \n",
    "                         gamma=0.05, \n",
    "                         subsample=0.6, \n",
    "                         min_child_weight=1, \n",
    "                         random_state =0, \n",
    "                         booster='gbtree', \n",
    "                         learning_rate=0.05, \n",
    "                         max_depth=3, \n",
    "                         reg_lambda=0.1, \n",
    "                         reg_alpha=0.3, \n",
    "                         n_estimators=1500)\n",
    "\n",
    "best_XGBC.fit(X_norm, y)\n",
    "#best_XGBC.fit(X_train_norm, y)\n",
    "\n",
    "y_hat_ALL_xgbc_proba = best_XGBC.predict_proba(X_norm)[::,1]\n",
    "#y_hat_train_xgbc_proba = best_XGBC.predict_proba(X_train_norm)[::,1]\n",
    "#y_hat_valid_xgbc_proba = best_XGBC.predict_proba(X_valid_norm)[::,1]\n",
    "\n",
    "auc_score_ALL_xgbc = roc_auc_score(y, y_hat_ALL_xgbc_proba) * 100\n",
    "#auc_score_train_xgbc = roc_auc_score(y_test, y_hat_train_xgbc_proba) * 100\n",
    "#auc_score_valid_xgbc = roc_auc_score(y_test, y_hat_valid_xgbc_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.2f}%  of XGBoost Classifier Model on ALL the data.\".format(auc_score_ALL_xgbc))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of XGBoost Classifier Model on the training data.\".format(auc_score_train_xgbc))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of XGBoost Classifier Model on the validation data.\".format(auc_score_valid_xgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score = 75.36%  of NN Model on ALL the data.\n"
     ]
    }
   ],
   "source": [
    "### Best MLPClassifier (Kaggle Score 0.74800)\n",
    "\n",
    "best_mlpc=MLPClassifier(hidden_layer_sizes=(4,2),\n",
    "                   activation='relu', \n",
    "                   solver='adam', \n",
    "                   alpha=0.00005, \n",
    "                   batch_size=4096, \n",
    "                   learning_rate='adaptive', \n",
    "                   learning_rate_init=0.00005, \n",
    "                   max_iter=2000, \n",
    "                   shuffle=True, \n",
    "                   tol=0.00001, \n",
    "                   verbose=False, \n",
    "                   momentum=0.9, \n",
    "                   early_stopping=False, \n",
    "                   validation_fraction=0.1, \n",
    "                   beta_1=0.9, \n",
    "                   beta_2=0.999, \n",
    "                   epsilon=1e-08, \n",
    "                   n_iter_no_change=10,\n",
    "                   random_state=0\n",
    "                   )\n",
    "\n",
    "best_mlpc.fit(X_norm, y)\n",
    "#best_mlpc.fit(X_train_norm, y_train)\n",
    "\n",
    "y_hat_ALL_mlpc_proba=best_mlpc.predict_proba(X_norm)[::,1]\n",
    "#y_hat_train_mlpc_proba=best_mlpc.predict_proba(X_train_norm)[::,1]\n",
    "#y_hat_valid_mlpc_proba=best_mlpc.predict_proba(X_valid_norm)[::,1]\n",
    "\n",
    "auc_score_ALL_mlpc = roc_auc_score(y, y_hat_ALL_mlpc_proba) * 100\n",
    "#auc_score_train_mlpc = roc_auc_score(y_test, y_hat_train_mlpc_proba) * 100\n",
    "#auc_score_valid_mlpc = roc_auc_score(y_test, y_hat_valid_mlpc_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.2f}%  of NN Model on ALL the data.\".format(auc_score_ALL_mlpc))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of NN Model on the training data.\".format(auc_score_train_mlpc))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of NN Model on the validation data.\".format(auc_score_valid_mlpc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogReg</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.143061</td>\n",
       "      <td>0.101987</td>\n",
       "      <td>0.190536</td>\n",
       "      <td>0.265471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211016</td>\n",
       "      <td>0.170361</td>\n",
       "      <td>0.157204</td>\n",
       "      <td>0.241808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.299475</td>\n",
       "      <td>0.266636</td>\n",
       "      <td>0.292053</td>\n",
       "      <td>0.247996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745033</td>\n",
       "      <td>0.778167</td>\n",
       "      <td>0.681992</td>\n",
       "      <td>0.749023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.686405</td>\n",
       "      <td>0.729042</td>\n",
       "      <td>0.661039</td>\n",
       "      <td>0.749023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LogReg  LinearSVC  XGBClassifier  MLPClassifier  target\n",
       "0  0.143061   0.101987       0.190536       0.265471       0\n",
       "1  0.211016   0.170361       0.157204       0.241808       0\n",
       "2  0.299475   0.266636       0.292053       0.247996       0\n",
       "3  0.745033   0.778167       0.681992       0.749023       0\n",
       "4  0.686405   0.729042       0.661039       0.749023       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_ALL = pd.DataFrame( {'LogReg': y_hat_ALL_logit_proba.ravel(),\n",
    "     'LinearSVC': y_hat_ALL_cclf_proba.ravel(),\n",
    "     'XGBClassifier': y_hat_ALL_xgbc_proba.ravel(),\n",
    "      'MLPClassifier': y_hat_ALL_mlpc_proba.ravel(),\n",
    "        'target': y\n",
    "    })\n",
    "\n",
    "#base_predictions_train = pd.DataFrame( {'LogReg': y_hat_train_logit_proba.ravel(),\n",
    "#     'LinearSVC': y_hat_train_cclf_proba.ravel(),\n",
    "#     'XGBClassifier': y_hat_train_xgbc_proba.ravel(),\n",
    "#     'MLPClassifier': y_hat_train_mlpc_proba.ravel(),\n",
    "#     'target': y_train\n",
    "#    })\n",
    "\n",
    "#base_predictions_valid = pd.DataFrame( {'LogReg': y_hat_valid_logit_proba.ravel(),\n",
    "#     'LinearSVC': y_hat_valid_cclf_proba.ravel(),\n",
    "#     'XGBClassifier': y_hat_valid_xgbc_proba.ravel(),\n",
    "#     'MLPClassifier': y_hat_valid_mlpc_proba.ravel(),\n",
    "#     'target': y_test\n",
    "#    })\n",
    "\n",
    "base_predictions_ALL.head()                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score = 75.55%  of Stacked LogReg Model on ALL the data.\n"
     ]
    }
   ],
   "source": [
    "#Stacked Model Predictions:\n",
    "#(C=0.001, Kaggle Score=0.74718)\n",
    "#(C=0.005, Kaggle Score=0.74820)\n",
    "#(C=0.01, Kaggle Score=0.74825)\n",
    "#(C=0.1, Kaggle Score=0.0.74770)\n",
    "#(C=0.01 minus XGBC, Kaggle Score=0.74760)\n",
    "#(C=1 minus XGBC, Kaggle Score=0.74873)\n",
    "#(C=0.5 minus XGBC, Kaggle Score=0.74866)\n",
    "#(C=1 minus XGBC & LogReg, Kaggle Score=0.74837)\n",
    "#(C=1 minus XGBC & linearSVC, Kaggle Score=0.74834)\n",
    "\n",
    "\n",
    "final_stack_LR_ALL=LogisticRegression(C=1, \n",
    "                solver='lbfgs', \n",
    "                penalty='l2',  \n",
    "                fit_intercept=True, \n",
    "                max_iter=200,\n",
    "                random_state=0\n",
    "                )\n",
    "\n",
    "final_stack_LR_ALL.fit(base_predictions_ALL.drop(columns = ['XGBClassifier', 'target']), base_predictions_ALL['target']) \n",
    "#final_stack_LR_train.fit(base_predictions_train.drop(columns = ['target']), base_predictions_train['target']) \n",
    "\n",
    "y_hat_ALL_stack_LR_proba=final_stack_LR_ALL.predict_proba(base_predictions_ALL.drop(columns = ['XGBClassifier', 'target']))[::,1] \n",
    "#y_hat_train_stack_LR_proba=final_stack_LR_ALL.predict_proba(base_predictions_train.drop(columns = ['target']))[::,1] \n",
    "#y_hat_valid_stack_LR_proba=final_stack_LR_ALL.predict_proba(base_predictions_valid.drop(columns = ['target']))[::,1] \n",
    "\n",
    "auc_score_ALL_stack_LR = roc_auc_score(y, y_hat_ALL_stack_LR_proba) * 100\n",
    "#auc_score_train_stack_LR = roc_auc_score(y_train, y_hat_train_stack_LR_proba) * 100\n",
    "#auc_score_valid_stack_LR = roc_auc_score(y_test, y_hat_valid_stack_LR_proba) * 100\n",
    "\n",
    "print(\"ROC_AUC Score = {:.2f}%  of Stacked LogReg Model on ALL the data.\".format(auc_score_ALL_stack_LR))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of Stacked LogReg Model on the training data.\".format(auc_score_train_stack_LR))\n",
    "#print(\"ROC_AUC Score = {:.2f}%  of Stacked LogReg Model on the validation data.\".format(auc_score_valid_stack_LR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score = 74.92%  of Logistic Regression Model on ALL the data.\n",
      "ROC_AUC Score = 74.93%  of LinearSVC Model on ALL the data.\n",
      "ROC_AUC Score = 76.05%  of XGBoost Classifier Model on ALL the data.\n",
      "ROC_AUC Score = 75.36%  of NN Model on ALL the data.\n",
      "ROC_AUC Score = 75.55%  of Stacked LogReg Model on ALL the data.\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC_AUC Score = {:.2f}%  of Logistic Regression Model on ALL the data.\".format(auc_score_ALL_logit))\n",
    "print(\"ROC_AUC Score = {:.2f}%  of LinearSVC Model on ALL the data.\".format(auc_score_ALL_cclf))\n",
    "print(\"ROC_AUC Score = {:.2f}%  of XGBoost Classifier Model on ALL the data.\".format(auc_score_ALL_xgbc))\n",
    "print(\"ROC_AUC Score = {:.2f}%  of NN Model on ALL the data.\".format(auc_score_ALL_mlpc))\n",
    "print(\"ROC_AUC Score = {:.2f}%  of Stacked LogReg Model on ALL the data.\".format(auc_score_ALL_stack_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of Stacked Model for the Kaggle Test Dataset \n",
    "\n",
    "data_test = pd.read_csv(\"./data/test.csv\", sep = \",\")\n",
    "\n",
    "\n",
    "znormalizer.fit(X[num_cols])\n",
    "data_test_norm = pd.DataFrame(znormalizer.transform(data_test[num_cols]), columns = num_cols)\n",
    "\n",
    "y_hat_test_logit_proba = best_LR.predict_proba(data_test_norm)[::,1]\n",
    "y_hat_test_cclf_proba = cclf.predict_proba(data_test_norm)[::,1]\n",
    "y_hat_test_xgbc_proba = best_XGBC.predict_proba(data_test_norm)[::,1]\n",
    "y_hat_test_mlpc_proba = best_mlpc.predict_proba(data_test_norm)[::,1]\n",
    "\n",
    "base_predictions_test = pd.DataFrame( {'LogReg': y_hat_test_logit_proba.ravel(),\n",
    "     'LinearSVC': y_hat_test_cclf_proba.ravel(),\n",
    "     'XGBClassifier': y_hat_test_xgbc_proba.ravel(),\n",
    "      'MLPClassifier': y_hat_test_mlpc_proba.ravel()\n",
    "    })\n",
    "\n",
    "\n",
    "test_predict = final_stack_LR_ALL.predict_proba(base_predictions_test.drop(columns = ['XGBClassifier']))[::,1]\n",
    "test_predict=test_predict.astype(float)\n",
    "array=np.array(test_predict).tolist()\n",
    "df_stack_LogReg=pd.DataFrame(data_test['id'])\n",
    "df_stack_LogReg['id'] = df_stack_LogReg['id'].astype(int)\n",
    "df_stack_LogReg['target'] = np.array(array)\n",
    "df_stack_LogReg.to_csv('Tab-Nov-2021_stacked_LogReg_final.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of MLPClassifier (fitted above and used in the stacked model) for the Kaggle Test Dataset\n",
    "\n",
    "test_predict = best_mlpc.predict_proba(data_test_norm)[::,1]\n",
    "test_predict=test_predict.astype(float)\n",
    "array=np.array(test_predict).tolist()\n",
    "df_mlpc=pd.DataFrame(data_test['id'])\n",
    "df_mlpc['id'] = df_mlpc['id'].astype(int)\n",
    "df_mlpc['target'] = np.array(array)\n",
    "df_mlpc.to_csv('Tab-Nov-2021_MLPClassifier_final.csv', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
